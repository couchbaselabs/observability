# Contributing to CMOS

Thank you for taking the time to contribute to CMOS! This guide is a set of guidelines as well as tips to make contributing easier.

## Reporting Issues

All issues related to CMOS are tracked on the [CMOS project](https://issues.couchbase.com/browse/CMOS) on the Couchbase JIRA. The project is public, as are the vast majority of issues, so feel free to file one if you spot an issue or have an idea for an improvement. Please don't keep these to yourself, filing an issue is helpful even if you don't intend to write the code yourself!

When filing an issue, please set the appropriate type (bug / improvement / new feature / task) and components.

## Code Style Guidelines

As CMOS is an amalgamation of various other projects, as well as some code of our own, we use various languages and tools.

The majority of these standards are enforced by linters - you can run all the linters by running `make lint`. If this passes, your code is probably good to go!

### Golang (Configuration Service)

In general, follow [gofumpt](https://github.com/mvdan/gofumpt). We use [golangci-lint](https://golangci-lint.run/) to enforce it.

### Bash (testing)

Run shellcheck on your code (this will be done automatically as part of the CI process).

By convention, use `lower_snake_case` for variables that only live inside the current function / test case, and `UPPER_SNAKE_CASE` for global variables.

### YAML (configuration files and Ansible playbooks)

Run yamllint and yamlfmt over your code, this will ensure it adheres to the style.

### Dockerfiles

Run hadolint over your files.

## Code Contribution Workflow

To start, follow the setup instructions in README.md.

Please use a descriptive Git branch name - ideally every change should be associated with a CMOS issue, so name your branch something like `CMOS-1234`.

Please follow this format for your commit messages, as this means they will automatically be associated with Jira tickets when you submit them for review:


> CMOS-1234: Fix the frobnicator
>
> A longer description of the background to this commit and the issue it fixes. Sometimes commit messages can be longer than the actual code changes, in which case having the additional context is invaluable.
>
> Write your commit message in the imperative: "Fix bug" and not "Fixed bug" or "Fixes bug."  This convention matches up with commit messages generated by commands like git merge and git revert.
>
> Include a brief statement on how you've tested your change, both automatically and manually as applicable - this will make it easier for maintainers to validate it.

## Pre-Commit Checklist

Before committing your changes, it's a good idea to run through this checklist. All of this is also enforced by automated CI, so you will not be able to submit your changes unless this passes, but running it locally may save you time.

* Does it work? (`make container`, then run the built image and test your feature / bug fix - note that if you do not have access to the couchbaselabs GitHub organisation you may not be able to do this, in this case skip this step and a maintainer can test it for you)
* Does it work in the OSS build (i.e. without the proprietary Couchbase Cluster Monitor)? (Run `make container-oss` and repeat the above)
* Do the linters pass? (`make lint`)
* Do the tests pass? (See below)
* If you have added substantial new code, is it covered by tests? (Not obligatory, but it's much easier than writing them after the fact!)
* If you have added any new third party components that are not tracked by go.mod or other package managers, have you added them to the `CONTRIBUTORS` and `README.md` files?
* If you have left any TODO comments, have you filed an associated CMOS issue? (Otherwise they may get forgotten.)
* If you have made changes to the build or packaging infrastructure, have you validated they will work with Couchbase's internal build infrastructure? (If you're not sure what this means, just ask a maintainer, and they'll help you out.)
* If you update the README file, have you updated the AsciiDoc version to go with it? (Run `make docs` and check in the changes)
* If you have made any changes to Grafana dashboards, have you included a screenshot? If appropriate, highlight any areas you have changed. (It means we don't need to start up an instance just to see how it looks.)

Once all the above can be ticked off, go ahead and file a pull request! If you are not a member of the couchbaselabs GitHub organization, you may need to fork the repository - the process is explained on this [GitHub help article](https://docs.github.com/en/get-started/quickstart/contributing-to-projects).

When your pull request is in, it will automatically have a battery of automatic tests and linters run against it, and it will be reviewed by a human (another developer on the project). If either of these come back to you with change requests, don't panic - simply fix up your code, push a new commit, and repeat the process until it is ready for merge. Don't feel put down if we request changes - even our most experienced developers rarely have a perfect PR on the first try.

## Testing

The testing philosophy of this project is described below - it is somewhat unconventional, since the project is not a single piece of code but rather an amalgamation of various other tools all plumbed together.

We need to verify the following key use cases:

* Out of the box defaults provided for simple usage to give a cluster overview
* Customization of rules and integrate into existing pipeline

In two separate infrastructures:

* Deploying microlith to Kubernetes using CAO, automatic service discovery
 ** Without CAO still possible but not tested
 ** Can also mix-and-match this with on-premise cluster (COS in k8s, Couchbase Server on premise)
* Deploying on-premise using manual configuration with the microlith
 ** Remote end point or in Vagrant as well

We need to test the following aspects:

* Prometheus endpoint is available from the microlith
* Adding the Couchbase Server instances to be monitored
* Couchbase Server metrics are available (using the exporter pre 7.0) from the microlith endpoint
 ** PromQL or promcli tooling can verify this
* Default alerting rules are triggered under appropriate failures
 ** Defaults in general just work out of the box
* Custom alerting rules can be provided
 ** Extend existing
 ** Replace defaults
 ** Disable defaults
* Grafana dashboards are available from the microlith
* Custom dashboards can be provided to the microlith
 ** We can query the REST API for this information, i.e. what rules are present and firing, etc.
* Loki endpoint is available from the microlith
 ** LogQL can verify this and that there is some data (need to ensure we send some logs)
* Components within the microlith can be enabled or disabled
 ** Repeat one of the previous tests (e.g. Loki) with the component disabled and confirm the test fails.
* Reproducible ephemeral container with custom configuration via GitOps
 ** Configuration of cluster connection & credentials
 ** Addition of custom alerts and tuning/inhibition of those alerts, plus addition of custom dashboards
* Integration with an existing stack
 ** Use Grafana operator here to create a separate stack in another namespace and demonstrate we can use this.

Variation points:

* Clusters with and without Prometheus end points
* Clusters using CBS 7.0+ and Prometheus exporter
* Clusters with different credentials
* Clusters using different versions of Couchbase Server
* In same namespace and separate namespaces
* With and without the useful extras like kube-state-metrics and eventrouter
* CE and EE clusters (not with CAO though for EE)
* On-prem and CAO clusters mixed together for monitoring

Our tests are implemented in Bash using the [BATS framework](https://bats-core.readthedocs.io/en/stable/).

CMOS targets three deployment platforms of Couchbase Server: "native" (bare-metal or VMs), "containers" (Docker or otherwise), and "kubernetes" (using the [Couchbase Autonomous Operator](https://www.couchbase.com/products/cloud/kubernetes)). Each of these suites has its own set of "integration" tests, in the `testing/bats/integration/{native,containers,kubernetes}` directories. There is also a "smoke" suite of tests that are run against all deployment models.

You can run each platform's tests by running `make test-native`, `make test-containers`, or `make test-kubernetes`, or you can run them all by running `make test` (this may take a while!). You can also specify which test suite to run, e.g. `make -e TEST_SUITE=smoke test-native`.

To run each platform's tests, you will need:

* Native: [Vagrant](http://vagrantup.com/), [VirtualBox](https://www.virtualbox.org/), and [Ansible](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html)
* Containers: a Docker daemon (on Windows or macOS you can use Docker Desktop)
* Kubernetes: same as above, plus either a running Kubernetes cluster or [kind](https://kind.sigs.k8s.io/)
  * If you use the latter, set the environment variable `SKIP_CLUSTER_CREATION=no` and the tests will take care of starting up an isolated cluster.

If your tests fail, and you want to poke around in the environment they were running in to understand why, set the environment variable `SKIP_TEARDOWN=true`. Note that this means you will have to clean up yourself afterwards.

### Automation

These tests are also run automatically using GitHub Actions. However, since setting up VMs and a Kubernetes cluster can be slow, we *only* run the containers smoke suite on pull requests. We run the full suite of tests every night, or manually upon request by a maintainer.

## Documentation

Documentation is done using [Asciidoc](https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/) for all Couchbase products.
The specific flavour we use is [Antora](https://antora.org/).

The only exception here is for developer documentation used directly from Github, i.e. this guide.

### Useful Tools

You can preview AsciiDoc code in a number of different ways.

#### Asciidoctor.js Preview

This is a browser plugin that detects and renders AsciiDoc, and is available for [Chrome](https://chrome.google.com/webstore/detail/asciidoctorjs-live-previe/iaalpfgpbocpdfblpnhhgllgbdbchmia?hl=en), and [Firefox](https://addons.mozilla.org/en-GB/firefox/addon/asciidoctorjs-live-preview/).
Simply specify a URI e.g. `file:///home/src/github.com/couchbaselabs/observability/docs/modules/ROOT/pages/index.adoc`, and it will update every time you save.

#### Github branch

Ensure that the documentation looks correct when present in Github.

#### CMOS container

Ensure that the documnetation looks correct when viewed via the landing page.

If there are certain aspects of the documentation that are only relevant when packaged inside the container, use `ifdef::env-packaged[]` to delimit these.
For example:

```asciidoc
ifdef::env-packaged[]
This text will only appear inside the container. It will not appear on docs.couchbase.com.
endif::env-packaged[]
```

Similarly, you can use `ifndef` to hide certain content when inside the container.
For example:

```asciidoc
ifndef::env-packaged[]
This text will only appear on docs.couchbase.com and on GitHub. It will not appear inside the container.
endif::env-packaged[]
```

### Site Layout

Important things about this repository:

[`docs/antora-container-playbook.yml`](./docs/antora-container-playbook.yml)
This is the document generation configuration for the container.
The product `title` should not be changed, unless PM ask for it as a branding exercise.
The `start_page` is the landing/default page for the repository.
Finally the `nav` defines the navigation menu for the repository.

* [`docs/antora-gh-playbook.yml`](./docs/antora-gh-playbook.yml)
  * This is the document generation configuration for the Github action on the `main` branch.
  * It will update the published version here: https://labs.couchbase.com/observability/

* [`docs/user/modules/ROOT/nav.adoc`](./docs/modules/ROOT/nav.adoc)
  * Defines the navigation menu for the repository.
  * The formatting is defined below.

* [`docs/user/modules/ROOT/pages/`](docs/modules/ROOT/pages/)
  * These are the main pages for the documentation.
  * The formatting is defined below.

* [`docs/user/modules/ROOT/partials/`](docs/modules/ROOT/partials/)
  * These define partial documentation, or snippets.
  * The formatting is the same as for documentation.

* [`docs/user/modules/ROOT/assets/images/`](docs/modules/ROOT/assets/images/)
  * These define any images included in documentation.
  * The formatting is defined below.
  * To ensure these are rendered correctly, any page using them should include the below snippet at the top:
  ```
  ifdef::env-github[]
  :imagesdir: https://github.com/couchbaselabs/observability/raw/main/docs/modules/ROOT/assets/images
  endif::[]
  ```

### Navigation Layout

When writing nav entries keep a few things in mind:

* The title of the entry, must match the title of the document it refers to
* Any level in the nav should aim to have about 10 entries at most, beyond this people cannot find things as they are overwhelmed
* The top level nav entries (learn, manage, etc.) should be consistent across all Couchbase products, don't touch these (even if they are nonsense, and should be concepts, tasks, etc.)

### Documentation Layout

Before writing any technical documentation, first thoroughly read [Write the Docs](https://www.writethedocs.org/).

Every document *must*:

* Have a title that corresponds to a nav entry with the same name
* Have an abstract
* Use white space to separate elements e.g. don't butt titles and paragraphs together
* Use one source line per sentence, this aids in diffing and code review
* Accompany tables and images with a title
* Use block syntax for admonitions
* Use attributes for versions where appropriate, so they update automatically over time
* Use xref, not link
* Use US English spelling

Every document should:

* Not repeat anything else, use links to avoid duplication -- don't repeat yourself (DRY)
* Have links at the bottom of the content to flow from one topic to the next
* Use diagrams where appropriate -- a picture paints a thousand words

#### Documentation Linting

You can run `make lint` to perform automated testing on your code this will:

* Spell check your work
* Ensure your AsciiDoc is will formed (TBD)
* Ensure cross-references point to something (TBD)

On the topic of spell checking, we filter out a lot of AsciiDoc commands and verbatim blocks.
By convention references to resources or tools e.g. `collectinfo` are surrounded by backticks (inline verbatim), and are filtered out.
Do not add these to the dictionary, we use their absence to enforce the use of backticks and consistent presentation.
When you think you need to add a word to the dictionary, please check to see if it already exists in a different form.
This is because some brand names e.g. Red Hat, should be a certain way for correctness and consistency.

### Image Layout

Images are all created with [diagrams.net](https://diagrams.net).
There's no real style defined for these, but try to keep things consistent with existing images e.g. default font size, Arial face.

### Reviewing Documentation

It is your job as reviewer to do the following:

* Check the actions pass
  * The author may not have spell checked
  * May not have working syntax
  * May have broken links
* Review the generated HTML output
  * Does it look broken or inconsistent anywhere?
* Do a technical review
  * Have *all* the navigation, documentation, and image layout conventions been followed.
* Then, and only then, can you give it approval to merge.
