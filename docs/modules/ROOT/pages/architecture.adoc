= Architecture

A Grafana-based stack has been selected for a few reasons:

* Already in use with Prometheus exporter and similar on Couchbase Server
* Industry standard and OSS with various integration points for other pipelines
* Existing options to scale from single node up to cloud scale easily

We expose Prometheus endpoints already for node-level information on a Couchbase Server instance.
Recently we have exposed logs using Fluent Bit, primarily for kubernetes based solutions but this can be deployed on-premise as well.

Couchbase have a proprietary project that provides cluster-level information via a Prometheus endpoint: https://github.com/couchbaselabs/cbmultimanager
This integrates Couchbase knowledge and best practices into a reusable component. We can then reuse this component in the monitoring stack here as it provides a Prometheus endpoint.

Our observability stack is therefore a combination of Couchbase-specific components that provide that discrete knowledge and monitoring of the Couchbase cluster which are then plumbed into a generic Grafana pipline like below.

.CMOS Architecture
image::healthcheck-blocks.png[]

A complete working stack is provided with a Grafana UI to access it all.

We also provide the various Prometheus endpoints for people who want to plumb it into another stack, or federate Prometheus instances or some other alternative.
They can reuse all the configuration provided, just not use Grafana for example.

Configuration points are also provided to tune the various alerts, dashboards and other configuration for a particular deployment, although basic deployment will provide a configured best practice version that is fully usable.

== Next steps

* xref:deployment-microlith.adoc[Microlith container deployment]
* xref:cluster-monitor.adoc[Couchbase Cluster Monitor component]
* xref:deployment-onpremise.adoc[On-premise deployment]
* xref:tutorial-onpremise.adoc[On-premise example]
